{"docs":[{"location":"/paradox.json","text":"","title":""},{"location":"/index.html","text":"","title":"Sysiphos"},{"location":"/index.html#sysiphos","text":"Sysiphos is a graph-based task scheduler.","title":"Sysiphos"},{"location":"/index.html#why-","text":"After looking at projects like Airflow, Chronos or Oozie there seems to be a place for a solution that is\nproviding a rich language agnostic scheduler DSL independent of a (technical) domain or focus area like Hadoop not reinventing the wheel usable with minimal dependencies JVM-based developed with an API first UI approach\nSysiphos wants to be that solution.\nThat being that, Sysiphos is heavily influenced by the usage of the above mentioned tools and tries to pick the best features of each. Its currently not a feature-rich as any of those solutions and provides basic scheduling.","title":"Why?"},{"location":"/index.html#comparison","text":"Sysiphos Airflow Oozie Definition Format Json Python XML Definition Model DAG DAG Workflow Graph Target Group JVM-minded, admins Python-minded, admins Hadoop Users Dependencies RDBMS (H2, MySQL, Postgres) RDBMS (MySQL, Postgres), Celery (Redis) Hadoop (HUE, HDFS) Monitoring Support StatsD, Prometheus StatsD ? Packaging tar.gz, docker image pip, community docker image Part of the Hadoop distribution Integration Support 100+ components via Camel many community contributed operators, sensors etc. none Workflow Pattern Support basic (sequence, trigger) advanced (sequence, branching, trigger, sub-dag) basic (sequence, branching) Data Sharing Concept local, dynamic (instance context values, extractions) global, static (XComs, Variables) none Execution Model actors, streams (internal queues) threads, external queues intertwined with the Yarn application model Scale high volume, streaming (tasks / seconds) low volume, batching (tasks / minute / hour) low volume, batching High Availability Akka Clustering (WIP) via Celery worker scaling via Hadoop API self documenting GraphQL HTTP API experimental HTTP API (only execute instance, only one per DAG / second) SOAP UI single page application (API-powered) form-based HUE, ExtJS Application\nSee the Introduction to read about the core concepts.","title":"Comparison"},{"location":"/intro.html","text":"","title":"Introduction"},{"location":"/intro.html#introduction","text":"In Sysiphos workflows are defined with by a JSON object:\n{\n  \"id\" : \"new-flow\",\n  \"tasks\" : [{\n    \"id\" : \"new-task\",\n    \"type\" : \"shell\",\n    \"command\" : \"curl https://api.chucknorris.io/jokes/random?category=${category!\\\"dev\\\"}\",\n    \"children\" : [\n      {\n        \"id\" : \"new-task\",\n        \"type\" : \"shell\",\n        \"command\" : \"echo I am child task, I get triggered when my parent is done. \"\n      }\n    ]\n  }]\n}\nIn our context we also call this the Flow Definition. A Flow Definition has a unique ID and a list of root tasks, that describes the work to be done. Every task can have a list of child tasks that get executed after the parent task has successfully finished its work.\nThis task structure lead to a tree (a Directed Acyclic Graph, short DAG) of tasks that should be executed.\nA flow definition can have one or more schedules assigned to it, that will trigger the execution repeatedly.\nWhen Sysiphos decides to execute a flow definition (because of the schedule or because it was triggered by the API) it will create a Flow Instance with a reference to the ID of a definition.\nA flow instance has have a Context which is a dictionary of values that can be seen as additional attributes that define the instance. This context is available for string interpolation in tasks that provide some kind of template.\nNext it will also create Flow Task Instance for the first root task and try to execute it. Task will per default be retried 3 times if a failure happens.\nAll of these entities allow a granular tracking and control of the execution. To handle the execution of multiple flow instances in parallel Sysiphos uses Actors.\nSee Execuction Model for a more detailed overview of the interaction of the actors with the introduces entities.","title":"Introduction"},{"location":"/execution-model.html","text":"","title":"Execution Model"},{"location":"/execution-model.html#execution-model","text":"The execution model of Sysiphos is implemented by an actor system using Akka.\nEvery entity from the Introduction has a corresponding actor which updates the underlying repository for that entity:\nThere is a singleton actor to control the time based aspects of the scheduling which also acts as supervisor for the Flow Instance actors.\nThese instance actors will spawn Flow Task Instance actors matching the parent-child relation of the tasks in the definition.\nIf a instance should be executed and the number of instances to consider for execution depend on the parallelism options in the flow definition:\nThe task instance actors are responsible for executing the task and logging the results, which differs depending on the task type (see Tasks):\nDepending on the result of the execution, the state of the task instance and the corresponding flow instance will be updated. Flow instances with tasks that still have retires are still considered as running executions:\nThe following state transitions are possible for an flow instance:","title":"Execution Model"},{"location":"/concurrency.html","text":"","title":"Concurrency"},{"location":"/concurrency.html#concurrency","text":"Sysiphos allows to specify concurrency on both the flow instance and the task instance level (see Execution Model for reference).","title":"Concurrency"},{"location":"/concurrency.html#instance-level","text":"The number of running instances can be controlled the following properties on the flow definition:\nparallelism: Int sets how many instances are allowed to run in parallel, if there are more instances scheduled they will stay in initial state until the older instances are done latestOnly : Boolean allows the scheduler to skip instances that are scheduled, but would lead to the same execution. Same meaning that they execute the same flow definition with the same context values. This could occur when the instance execution is slow, so that the schedule (but also calls to the API) leads to more of the same instances. Skipping such instances can save time and resources.","title":"Instance Level"},{"location":"/concurrency.html#task-level","text":"Every instance actor is the holder of a task stream with a source queue that can be controlled via the following properties on the flow definition:\ntaskParallelism: Int defines how many tasks can run in parallel in a given instance taskRatePerSecond: Int defines how many tasks will at max be done per second\nThe task parallelism also defines how many task actors will be available for the work generated by the task stream. There is a back-pressure mechanism in place, so new instances will only be executed if the of pool task actors has the capacity. Otherwise the enqueueing into the queue of the task stream will be denied.\nThe example in the diagram shows a graph with two tasks running in parallel.\nIn this state only Task 1 would be considered runnable since its the only child of a done parent (the root is considered done) but assuming a taskParallelism of 2, the instance actor can not enqueue this task.\nOnce Task 4 is done, the instance actor will try to enqueue both the tasks Task 1, Task 6 and Task 7 from which only one will be enqueued.","title":"Task Level"},{"location":"/run.html","text":"","title":"Run"},{"location":"/run.html#run","text":"","title":"Run"},{"location":"/run.html#docker","text":"A docker image is provided, so you can just run it.\ndocker run -p 9090:8080 flowtick/sysiphos:latest\nWill run Sysiphos with an in-memory database, that will accessible in the browser at http://localhost:9090.\nSee also the docker-compose example, which is using MySQL:\nversion: '3.1'\n\nservices:\n\n  db:\n    image: mysql:5.5\n    restart: always\n    environment:\n      MYSQL_ROOT_PASSWORD: example\n      MYSQL_DATABASE: sysiphos\n    networks:\n      main:\n        aliases:\n          - db\n  # to have a look at the tables etc.\n  adminer:\n    image: adminer\n    restart: always\n    ports:\n    - 9091:8080\n\n  sysiphos-master:\n    image: flowtick/sysiphos:latest\n    depends_on:\n      - db\n    ports:\n      - 1040:8080\n      - 1050:8558\n      - 1060:9095\n    networks:\n      main:\n        aliases:\n          - sysiphos-master\n    environment:\n      CLUSTER_ENABLED: \"true\"\n      CLUSTER_IP: \"sysiphos-master\"\n      ALLOW_MASTER: \"on\"\n      ENDPOINT1_IP: \"sysiphos-master\"\n      ENDPOINT2_IP: \"sysiphos-worker\"\n      DATABASE_PROFILE: mysql\n      DATABASE_URL: jdbc:mysql://db:3306/sysiphos\n      DATABASE_USER: root\n      DATABASE_PASSWORD: example\n      STATS_ENABLED: \"true\"\n      STATS_HOST: grafana\n\n  sysiphos-worker:\n    image: flowtick/sysiphos:latest\n    depends_on:\n      - db\n    ports:\n      - 2040:8080\n      - 2050:8558\n      - 2060:9095\n    networks:\n      main:\n        aliases:\n          - sysiphos-worker\n    environment:\n      CLUSTER_ENABLED: \"true\"\n      CLUSTER_IP: \"sysiphos-worker\"\n      ALLOW_MASTER: \"off\"\n      ENDPOINT1_IP: \"sysiphos-master\"\n      ENDPOINT2_IP: \"sysiphos-worker\"\n      DATABASE_PROFILE: mysql\n      DATABASE_URL: jdbc:mysql://db:3306/sysiphos\n      DATABASE_USER: root\n      DATABASE_PASSWORD: example\n      STATS_ENABLED: \"true\"\n      STATS_HOST: grafana\n\n  grafana:\n    image: kamon/grafana_graphite\n    ports:\n      - 3000:80\n      - 3001:81\n      - 8125:8125/udp\n      - 8126:8126\n      - 2003:2003\n    networks:\n      main:\n        aliases:\n          - grafana\nnetworks:\n  main:\nFull source at GitHub","title":"Docker"},{"location":"/run.html#from-source","text":"The server can also be run directly in the source directory via sbt\nsbt serverJVM/run -Dprop=value\nIn the example a system property with key prop is passed in.","title":"From Source"},{"location":"/monitoring.html","text":"","title":"Monitoring"},{"location":"/monitoring.html#monitoring","text":"Sysiphos uses kamon to export monitoring data. Currently it supports StatsD (for Graphite / Grafana) and Prometheus.\nSee the Configuration for the corresponding keys to enable it.\nOnce stats are enabled Prometheus metrics will be exposed on port 9095.\nYou can also download an example dashboard for Grafana.","title":"Monitoring"},{"location":"/tutorial.html","text":"","title":"Tutorial"},{"location":"/tutorial.html#tutorial","text":"First make sure Sysiphos is running and open the user interface in the browser.\nFollow the steps to create a new Flow Definition: Show GIF","title":"Tutorial"},{"location":"/tasks.html","text":"","title":"Tasks"},{"location":"/tasks.html#tasks","text":"The following sections will give you an overview on the available task types.","title":"Tasks"},{"location":"/tasks.html#shell-task","text":"{\n  \"id\": \"shell-flow\",\n  \"tasks\": [\n    {\n      \"id\" : \"task-id\",\n      \"type\" : \"shell\",\n      \"command\" : \"some command\",\n      \"shell\": \"bash\",\n      \"children\" : []\n    }\n  ]\n}\nFull source at GitHub\nWill execute the command and be considered successfully on exit code 0. Be aware that the shell is optional, if not specified the JVM process builder will be used to execute the command. If shell specific features like output piping etc. are needed, please set it accordingly.\nThe command property supports string interpolation.","title":"Shell Task"},{"location":"/tasks.html#trigger-task","text":"{\n  \"id\": \"trigger-flow\",\n  \"tasks\": [\n    {\n      \"id\" : \"task-id\",\n      \"type\" : \"trigger\",\n      \"flowDefinitionId\" : \"some-flow-id\",\n      \"tasks\" : []\n    }\n  ]\n}\nFull source at GitHub\nWill trigger the execution of the given flow definition id. The context values of the current flow will be copied over to the new instance.\nNote that the triggering instance will not wait for the completion of the triggered instance, once the instance is successfully created, the trigger task is considered done.","title":"Trigger Task"},{"location":"/tasks.html#string-interpolation","text":"Its possible to use freemarker expression to access the context of the instance or system properties on some tasks that support it.\nFor example, the execution of \"command\" : \"echo Hello ${name}\" in an instance that has the context value name with value World will print Hello World to the log.","title":"String Interpolation"},{"location":"/camel.html","text":"","title":"Camel Tasks"},{"location":"/camel.html#camel-tasks","text":"Sysiphos allows to use Apache Camel components via the usage of Camel URIs. This enables rich integration flows inside a flow definition.\nThe context values are available for string interpolation when using endpoints that can take a body.\nFollowing are some common examples of using the Camel Task.","title":"Camel Tasks"},{"location":"/camel.html#http","text":"{\n  \"id\": \"trigger-flow\",\n  \"tasks\": [\n    {\n      \"id\" : \"camel-get\",\n      \"type\" : \"camel\",\n      \"uri\" : \"http4://localhost:80/path?param=foo\",\n      \"headers\": {\n        \"Accept\": \"application/json\"\n      },\n      \"children\" : []\n    },\n    {\n      \"id\" : \"camel-post\",\n      \"type\" : \"camel\",\n      \"uri\" : \"http4://localhost:80/path\",\n      \"bodyTemplate\": \"{ \\\"param\\\" : \\\"${someContextKey}\\\" }\",\n      \"headers\": {\n        \"Content-Type\": \"application/json\"\n      },\n      \"extract\": [\n        {\n          \"type\": \"jsonpath\",\n          \"name\": \"result\",\n          \"expression\": \"$.data.value\"\n        }\n      ],\n      \"children\" : []\n    }\n  ]\n}\nFull source at GitHub\nIn this example are two HTTP tasks defined. The first one will do a GET-request due to the missing bodyTemplate and will add an Accept header to the request.\nThe second will replace the ${someContextKey} expression with the corresponding context value and do a POST including the Content-Type header.\nIts also possible to define the HTTP method and other options like timeouts etc via uri or header, see the http4 component reference.\nNote the extract-definition on this task. Its possible to extract a value from the response body via a JsonPath expression. So assuming that the response will be:\n{\n \"data\": {\n    \"value\": 42\n }\n}\nThere will be a new or updated context value with the name result and the value 42 in the flow instance. It is possible to add more than one extraction. On failures in the extraction the task will we considered failed (potentially going into retry).","title":"HTTP"},{"location":"/camel.html#slack","text":"{\n  \"id\": \"slack-flow\",\n  \"tasks\": [\n    {\n      \"id\" : \"send-slack-message\",\n      \"type\" : \"camel\",\n      \"uri\" : \"slack:#a-channel?webhookUrl=http://slack.com/services/a/b/c\",\n      \"bodyTemplate\": \"Hello ${subject}!\",\n      \"children\" : []\n    }\n  ]\n}\nFull source at GitHub\nThis task will send the message Hello World! to the slack channel a-channel given a flow instance with a context value with the name subject and value World.\nTo be able to use a slack task you need a webhook url that you can create in the configuration of your corresponding slack app.","title":"Slack"},{"location":"/camel.html#sql","text":"{\n  \"id\": \"slack-flow\",\n  \"tasks\": [\n    {\n      \"id\" : \"query-sql\",\n      \"type\" : \"camel\",\n      \"uri\" : \"sql:select 1+1 as result?dataSource=ds\",\n      \"children\" : [],\n      \"extract\": [\n        {\n          \"type\": \"simple\",\n          \"name\": \"result\",\n          \"expression\": \"${body.get(\\\"RESULT\\\")}\"\n        }\n      ],\n      \"registry\" : {\n        \"ds\" : {\n          \"type\": \"bean\",\n          \"fqn\": \"org.h2.jdbcx.JdbcDataSource\",\n          \"properties\" : {\n            \"url\" : \"jdbc:h2:somedb\",\n            \"user\": \"someuser\",\n            \"password\": \"somepassword\"\n          }\n        }\n      }\n    }\n  ]\n}\nFull source at GitHub\nThis task will execute the SQL query in the URI using the datasource specified in the registry with name ds. In this case it will return a single row with a column RESULT and the value 2. In Camel result sets will be transformed to collections, so a single result will be a Map and a bigger result set will become a List of Maps. Its possible to extract values from the result using a simple expression that can access values of the Camel exchange.\nIn the example the expression would extract the value 2 from the result map and store it as context value with the name result.","title":"SQL"},{"location":"/camel.html#java","text":"{\n  \"id\": \"bean-flow\",\n  \"tasks\": [\n    {\n      \"id\" : \"call-java\",\n      \"type\" : \"camel\",\n      \"uri\" : \"direct:start\",\n      \"to\": [\n        \"bean:myBean?method=doStuff\"\n      ],\n      \"children\" : [],\n      \"registry\" : {\n        \"myBean\" : {\n          \"type\": \"bean\",\n          \"fqn\": \"com.flowtick.sysiphos.example.MyClass\"\n        }\n      }\n    }\n  ]\n}\nFull source at GitHub\nThis task will create a new instance of type com.flowtick.sysiphos.example.MyClass using the default constructor. The bean is referenced by its registry name myBean to invoke the method doStuff:\npackage com.flowtick.sysiphos.example;\n\npublic class MyClass {\n    public void doStuff() {\n        System.out.println(\"doing stuff...\");\n    }\n}\nFull source at GitHub","title":"Java"},{"location":"/camel.html#other-camel-task-properties","text":"convertStreamToString: by default Sysiphos tries to convert Camel exchange bodies of type java.io.InputStream to the type String to allow multiple extractions. This can be disabled by setting to value false. exchangeType: can be one of procuder, consumer. This is useful to set for endpoints that allow both consuming and producing.","title":"Other Camel task properties"},{"location":"/camel.html#adding-more-components-or-own-java-classes","text":"To add more Camel components or you own Java classes, you currently need to copy the (component) jar and its dependencies to the lib (/opt/docker/lib in the docker image) folder of the Sysiphos package.\nYou can also add a component by extending the library dependencies of the build.sbt in the Sysiphos source folder and creating a custom image by running sbt docker:publishLocal.\nA more convenient way of providing jars might be added in the future.","title":"Adding more components or own Java classes"},{"location":"/configuration.html","text":"","title":"Configuration"},{"location":"/configuration.html#configuration","text":"Sysiphos allows configuration via Java system properties or environment variables.\nThe corresponding environment variable for a property is created by making it upper case with all . characters replaced by _.\nSo a.property.key becomes A_PROPERTY_KEY.\nSysiphos will first look for the property value, then for the corresponding environment variable and then fallback to default if possible.\nProperty Default Description database.url jdbc:h2:mem:sysiphos;DB_CLOSE_DELAY=-1 The JDBC URL to use database.user sa The JDBC user to use database.password empty string The JDBC password to use database.profile h2 The database type, currently one of (h2, mysql) logger.impl file The logger backend implementation, currently one of (file-direct, file-stream, s3, console), console will use stdout logger.stream.chunkSize 100 The number of lines to aggregate (chunking) before writing to the log backend, only applies to stream backends like s3 or file-stream logger.stream.queueSize 1000 The size of the queue used for interacting with the process output logger.file.baseDir /tmp (the value of java.io.tmpdir) The base directory to use for logging for the file based backends logger.s3.accessKey changeme The access key to use for logging to S3 (default credentials chain is checked first) logger.s3.secretKey changeme The secret key to use for logging to S3 (default credentials chain is checked first) logger.s3.bucket changeme The bucket to use for S3 logging, this can be seen as the root folder for logging http.bind.address 0.0.0.0 Address to use to bind the http server http.port 8080 Port to use to bind the http server stats.enabled false flag to enable to export operational statistics stats.host none Host of the stats server to use for StatsD stats.port 8125 Port of the stats server to use for StatsD instance.threads 10 number of threads to use for database access during instance execution api.threads 10 number of threads to use for api request handling task.retries.default 3 default number of retries for a task, if not specified otherwise task.retry.delay.default 18000 default number of seconds to wait until next try, if not specified otherwise","title":"Configuration"},{"location":"/build.html","text":"","title":"Build"},{"location":"/build.html#build","text":"Sysiphos uses sbt as build tool. It is assumed that you have installed.\nThe core libs should also work for older Scala versions, so remember to verify / run everything with the cross build prefix:\nsbt +compile\nsbt +test","title":"Build"},{"location":"/build.html#packaging","text":"Sysiphos uses sbt-native-packager, this allows to create multiple formats, see the documentation for details.\nExamples:\n# creates a deb file\nsbt debian:packageBin \n\n# create a zip package with start scripts\nsbt universal:packageBin \n\n# create a tar.gz package with start scripts\nsbt universal:packageZipTarball \n\n# create a local docker image\nsbt docker:publishLocal\nBuild packages can be found in server/jvm/target[/universal]","title":"Packaging"},{"location":"/build.html#publishing","text":"First build the docker image:\nsbt docker:publishLocal\nThis will create a latest tag and one for the current build version.\nThen login and push it:\ndocker login \n# enter your credentials\ndocker push flowtick/sysiphos:latest","title":"Publishing"},{"location":"/build.html#documentation","text":"Generate the site:\nsbt makeSite\nand check the result in target/site.\nIf it looks good and you have the permissions, you can push it to the GitHub Pages via:\nsbt ghpagesPushSite","title":"Documentation"},{"location":"/screenshots.html","text":"","title":"Screenshots"},{"location":"/screenshots.html#screenshots","text":"","title":"Screenshots"},{"location":"/screenshots.html#flow-editor","text":"Shows the source and the corresponding schedules.","title":"Flow Editor"},{"location":"/acknowledgments.html","text":"","title":"Acknowledgments"},{"location":"/acknowledgments.html#acknowledgments","text":"Sysiphos stands on the shoulders of giants. It is built using:\nScala Scala.js sbt Finch Sangria Akka circe Slick Binding.scala diode Freemarker cron4s\nMade in Berlin Logo by Nadine Rossa","title":"Acknowledgments"},{"location":"/license.html","text":"","title":"License"},{"location":"/license.html#license","text":"Sysiphos is published under the terms of the Apache 2.0 License\nApache License\n                        Version 2.0, January 2004\n                     http://www.apache.org/licenses/\n\nTERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n1. Definitions.\n\n   \"License\" shall mean the terms and conditions for use, reproduction,\n   and distribution as defined by Sections 1 through 9 of this document.\n\n   \"Licensor\" shall mean the copyright owner or entity authorized by\n   the copyright owner that is granting the License.\n\n   \"Legal Entity\" shall mean the union of the acting entity and all\n   other entities that control, are controlled by, or are under common\n   control with that entity. For the purposes of this definition,\n   \"control\" means (i) the power, direct or indirect, to cause the\n   direction or management of such entity, whether by contract or\n   otherwise, or (ii) ownership of fifty percent (50%) or more of the\n   outstanding shares, or (iii) beneficial ownership of such entity.\n\n   \"You\" (or \"Your\") shall mean an individual or Legal Entity\n   exercising permissions granted by this License.\n\n   \"Source\" form shall mean the preferred form for making modifications,\n   including but not limited to software source code, documentation\n   source, and configuration files.\n\n   \"Object\" form shall mean any form resulting from mechanical\n   transformation or translation of a Source form, including but\n   not limited to compiled object code, generated documentation,\n   and conversions to other media types.\n\n   \"Work\" shall mean the work of authorship, whether in Source or\n   Object form, made available under the License, as indicated by a\n   copyright notice that is included in or attached to the work\n   (an example is provided in the Appendix below).\n\n   \"Derivative Works\" shall mean any work, whether in Source or Object\n   form, that is based on (or derived from) the Work and for which the\n   editorial revisions, annotations, elaborations, or other modifications\n   represent, as a whole, an original work of authorship. For the purposes\n   of this License, Derivative Works shall not include works that remain\n   separable from, or merely link (or bind by name) to the interfaces of,\n   the Work and Derivative Works thereof.\n\n   \"Contribution\" shall mean any work of authorship, including\n   the original version of the Work and any modifications or additions\n   to that Work or Derivative Works thereof, that is intentionally\n   submitted to Licensor for inclusion in the Work by the copyright owner\n   or by an individual or Legal Entity authorized to submit on behalf of\n   the copyright owner. For the purposes of this definition, \"submitted\"\n   means any form of electronic, verbal, or written communication sent\n   to the Licensor or its representatives, including but not limited to\n   communication on electronic mailing lists, source code control systems,\n   and issue tracking systems that are managed by, or on behalf of, the\n   Licensor for the purpose of discussing and improving the Work, but\n   excluding communication that is conspicuously marked or otherwise\n   designated in writing by the copyright owner as \"Not a Contribution.\"\n\n   \"Contributor\" shall mean Licensor and any individual or Legal Entity\n   on behalf of whom a Contribution has been received by Licensor and\n   subsequently incorporated within the Work.\n\n2. Grant of Copyright License. Subject to the terms and conditions of\n   this License, each Contributor hereby grants to You a perpetual,\n   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n   copyright license to reproduce, prepare Derivative Works of,\n   publicly display, publicly perform, sublicense, and distribute the\n   Work and such Derivative Works in Source or Object form.\n\n3. Grant of Patent License. Subject to the terms and conditions of\n   this License, each Contributor hereby grants to You a perpetual,\n   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n   (except as stated in this section) patent license to make, have made,\n   use, offer to sell, sell, import, and otherwise transfer the Work,\n   where such license applies only to those patent claims licensable\n   by such Contributor that are necessarily infringed by their\n   Contribution(s) alone or by combination of their Contribution(s)\n   with the Work to which such Contribution(s) was submitted. If You\n   institute patent litigation against any entity (including a\n   cross-claim or counterclaim in a lawsuit) alleging that the Work\n   or a Contribution incorporated within the Work constitutes direct\n   or contributory patent infringement, then any patent licenses\n   granted to You under this License for that Work shall terminate\n   as of the date such litigation is filed.\n\n4. Redistribution. You may reproduce and distribute copies of the\n   Work or Derivative Works thereof in any medium, with or without\n   modifications, and in Source or Object form, provided that You\n   meet the following conditions:\n\n   (a) You must give any other recipients of the Work or\n       Derivative Works a copy of this License; and\n\n   (b) You must cause any modified files to carry prominent notices\n       stating that You changed the files; and\n\n   (c) You must retain, in the Source form of any Derivative Works\n       that You distribute, all copyright, patent, trademark, and\n       attribution notices from the Source form of the Work,\n       excluding those notices that do not pertain to any part of\n       the Derivative Works; and\n\n   (d) If the Work includes a \"NOTICE\" text file as part of its\n       distribution, then any Derivative Works that You distribute must\n       include a readable copy of the attribution notices contained\n       within such NOTICE file, excluding those notices that do not\n       pertain to any part of the Derivative Works, in at least one\n       of the following places: within a NOTICE text file distributed\n       as part of the Derivative Works; within the Source form or\n       documentation, if provided along with the Derivative Works; or,\n       within a display generated by the Derivative Works, if and\n       wherever such third-party notices normally appear. The contents\n       of the NOTICE file are for informational purposes only and\n       do not modify the License. You may add Your own attribution\n       notices within Derivative Works that You distribute, alongside\n       or as an addendum to the NOTICE text from the Work, provided\n       that such additional attribution notices cannot be construed\n       as modifying the License.\n\n   You may add Your own copyright statement to Your modifications and\n   may provide additional or different license terms and conditions\n   for use, reproduction, or distribution of Your modifications, or\n   for any such Derivative Works as a whole, provided Your use,\n   reproduction, and distribution of the Work otherwise complies with\n   the conditions stated in this License.\n\n5. Submission of Contributions. Unless You explicitly state otherwise,\n   any Contribution intentionally submitted for inclusion in the Work\n   by You to the Licensor shall be under the terms and conditions of\n   this License, without any additional terms or conditions.\n   Notwithstanding the above, nothing herein shall supersede or modify\n   the terms of any separate license agreement you may have executed\n   with Licensor regarding such Contributions.\n\n6. Trademarks. This License does not grant permission to use the trade\n   names, trademarks, service marks, or product names of the Licensor,\n   except as required for reasonable and customary use in describing the\n   origin of the Work and reproducing the content of the NOTICE file.\n\n7. Disclaimer of Warranty. Unless required by applicable law or\n   agreed to in writing, Licensor provides the Work (and each\n   Contributor provides its Contributions) on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n   implied, including, without limitation, any warranties or conditions\n   of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n   PARTICULAR PURPOSE. You are solely responsible for determining the\n   appropriateness of using or redistributing the Work and assume any\n   risks associated with Your exercise of permissions under this License.\n\n8. Limitation of Liability. In no event and under no legal theory,\n   whether in tort (including negligence), contract, or otherwise,\n   unless required by applicable law (such as deliberate and grossly\n   negligent acts) or agreed to in writing, shall any Contributor be\n   liable to You for damages, including any direct, indirect, special,\n   incidental, or consequential damages of any character arising as a\n   result of this License or out of the use or inability to use the\n   Work (including but not limited to damages for loss of goodwill,\n   work stoppage, computer failure or malfunction, or any and all\n   other commercial damages or losses), even if such Contributor\n   has been advised of the possibility of such damages.\n\n9. Accepting Warranty or Additional Liability. While redistributing\n   the Work or Derivative Works thereof, You may choose to offer,\n   and charge a fee for, acceptance of support, warranty, indemnity,\n   or other liability obligations and/or rights consistent with this\n   License. However, in accepting such obligations, You may act only\n   on Your own behalf and on Your sole responsibility, not on behalf\n   of any other Contributor, and only if You agree to indemnify,\n   defend, and hold each Contributor harmless for any liability\n   incurred by, or claims asserted against, such Contributor by reason\n   of your accepting any such warranty or additional liability.\n\nEND OF TERMS AND CONDITIONS\n\nAPPENDIX: How to apply the Apache License to your work.\n\n   To apply the Apache License to your work, attach the following\n   boilerplate notice, with the fields enclosed by brackets \"[]\"\n   replaced with your own identifying information. (Don't include\n   the brackets!)  The text should be enclosed in the appropriate\n   comment syntax for the file format. We also recommend that a\n   file or class name and description of purpose be included on the\n   same \"printed page\" as the copyright notice for easier\n   identification within third-party archives.\n\nCopyright 2017 Sysiphos contributors\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\nFull source at GitHub","title":"License"},{"location":"/scheduling.html","text":"","title":"Scheduling"},{"location":"/scheduling.html#scheduling","text":"It is possible to create a schedule to run flow definitions automatically.\nA schedule consists of a cron-like expression that defines the time intervals to wait between each run.\nSysiphos uses cron4s, which allows cron expressions that go from seconds to day of week in the following order:\nSeconds\nMinutes\nHour Of Day\nDay Of Month\nMonth\nDay Of Week","title":"Scheduling"},{"location":"/scheduling.html#examples","text":"0 0 12 * * ? \t#Fire at 12pm (noon) every day","title":"Examples"},{"location":"/scheduling.html#backfill","text":"Per default a schedule will back fill its schedule, which means that it will take the last schedule date as starting point to determine the next schedule date.","title":"Backfill"},{"location":"/scheduling.html#creating-a-schedule","text":"Schedules can be created in the API using the createFlowSchedule mutation, or in the corresponding UI section in the flow overview.","title":"Creating a schedule"},{"location":"/diagrams/HOWTO.html","text":"","title":"How to create or update diagrams"},{"location":"/diagrams/HOWTO.html#how-to-create-or-update-diagrams","text":"","title":"How to create or update diagrams"},{"location":"/diagrams/HOWTO.html#uml","text":"The UML plugins can be updated with any tool the understands PlantUML sources:\nPlantUML Server AsciidocFX markup\nAfter editing the image files should be updated.\n## Graph Diagrams (.graphml)\nGraph diagrams can be edited and exported with https://www.yworks.com/products/yed.","title":"UML"}]}